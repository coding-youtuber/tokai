ヒカキンがしたコメントをどうやって調べたか
実はプログラミングをクソ使っています
今からお前らでもわかるように
プロのエンジニアである私が
クソわかりやすい言葉で説明します
動画では東海オンエアのサムネイルを
ランダムのスライドショーで表示しておくので
プログラミングわかんねと思ったら
とりあえずサムネイルをぼけっと見ておいてください
今回東海オンエアのメインチャンネルにある
すべての通常動画についているコメントを収集しました
ライブとショート動画は除いていますが
コメント総数は900万件以上あります
クソ多いです
東海オンエアの視聴者は本当によくコメントします
クソ多いので
手作業でこの中からヒカキンのコメントを
探すのは不可能です
そこでプログラミングの出番です
プログラミングはプログラムを書くことを指します
コンピュータをこき使うために
人間はプログラムを書いてコンピュータに命令するんです
コンピュータは単純作業がクソ得意です
というか0と1しかわからないので単純作業しかできません
だから今回の企画に向いています
コメントがヒカキンのコメントかどうかを判断するだけなので
クソ単純作業なんです
ただ量がとんでもなく多いので人間には難しい
一方コンピュータは疲れてやめることはありません
では具体的な作業手順を説明します
手順１。東海オンエアの全ての動画IDを収集
手順２。各動画のコメントを収集
手順３。収集した動画とコメントをデータベースに保存
最後にSQLを書いてヒカキンのコメントを抽出します
データベースとはデータの保存や取得を
簡単にできるようにしたシステムのことです
SQLはデータベースを操作するために使います
プログラミング言語ではないですが
エンジニアの仕事でデータベースを扱うときはよく使うものです
まず手順１です
youtubeではすべての動画はIDを持っています
IDは動画と動画を見分けるための名前みたいなものです
普通に考えると動画のタイトルで良さそうですが
youtubeでは他の人が作った動画と
同じタイトルをつけることができます
これだと見分けがつかないのでIDに使えません
youtubeではIDにこのような文字列を使っています
この文字はクソ難しい数学を使って生成されています
今回は理解する必要はないので
わけのわからない文字だと思っていてください
そしてチャンネルにもチャンネルIDがあります
まず東海オンエアのメインチャンネルのIDを調べます
このサイトで調べました
このフォームにチャンネルのURLを入力します
これでチャンネルIDがわかります
次にプログラムを書いて
東海オンエアメインチャンネルの動画IDを収集します
プログラミング言語はpythonを使います
python以外の言語でも可能ですが
pythonが今回使いやすかったので
pythonを使います
まずpythonを簡単に動かすための準備をします
Google Driveを開いて
Google Colabのファイルを作成
そして!pip3 install scrapetubeを入力します
そうするとscrapetubeというライブラリがインストールできます
ライブラリとは便利プログラムをまとめたもの
インストールはGoogle Colabの環境に
プログラムをダウンロードして使える状態にすることを言います
インストールはちょうど
冷凍食品をレンジでチンして
食べられる状態にすることに似ています
そしてpythonのプログラムを書いて
動画をIDをテキストファイルに保存します
わけわからないと思いますが
概要欄にgoogle colabの
URLを置いておくのでそれを使ってください
このプログラムは何をしているかというと
パソコンで東海オンエアの
動画一覧を見るときにスクロールすると
古い動画が表示されます
またさらにスクロールすると
古い動画が表示されます
このスクロール操作は
普通は人間がやらないといけないですが
実はコンピュータに命令すれば
コンピュータが自動でやってくれます
その命令をpythonで書いています
自分で書くのはクソ大変なので
ライブラリを使っています
ライブラリは海外の開発者が作っています
動画IDは動画のURLに含まれています
URLは動画が置いてある場所を示す物です
Chromeでスクロールするたびに
動画が表示されますが
ここのリンクがURLになっています
このURLを読む行為もコンピュータに命令することができます
なのでスクロールするたびに
動画IDをURLから調べてそれをテキストファイルに保存しています
これで東海オンエアの通常動画の
動画IDを収集できました
2561本の動画がありました
手順２では各動画のコメントを収集します
ここでは別のライブラリを使います
youtube-comment-downloaderです
パソコンでyoutubeの動画を開くと
コメントが表示されます
これもスクロールすると
コメントがさらに表示される仕組みです
動画IDの収集と同様にコメントにおいても
スクロールを自動化して収集します
つまりpythonでプログラムを書き
プログラムによってChromeのようなブラウザを開き
動画のURLにアクセスしコメントを表示して
それを保存。保存できたら
されにスクロールそして新しいコメントが
表示されるのでまた保存
一番古いコメントが
表示されるまでこれを繰り返します
プログラムはこのような感じです
収集したプログラムは
JSONで保存されます
JSONはデータの種類とその値を
まとめて書く形式のことを言います
クソ使います
東海オンエアの動画は数千のコメントが付きます
1つの動画を収集するのに
数分かかることもあるので
2500もの動画のコメントを
すべて収集するのはクソ大変です
処理を高速化するために
並列処理のプログラムを
書いたりしました
このあたりは自分で書くのが大変なので
Chat GPT4の力を借りてます
手順３。収集した動画とコメントをデータベースに保存
ダウンロードしたJSONを使って
それをMySQLというデータベースに保存します
まずテーブルを作ります
テーブルはデータのまとまりです
Video,Channel,Commentを作りました
まず全ての動画をvideoテーブルに
保存します
事前に保存しておいた
動画IDのテキストファイルを使います
そしてまた新しいライブラリ
pytube（パイチューブ）を使います
これを使えば動画IDから
動画の情報を取得してJSONで保存できます
例えば動画の閲覧数、公開日時などがわかります
次に動画のJSONをデータベースに保存します
直接SQLを書いても良いのですが
大変なので
prismaというライブラリを使います
prismaはjavascriptで動きます
ブラウザなどのクライアントサイドで
動くjavascriptに対して
サーバーサイドで動くjavascriptを
nodejs（ノードジェイエス）といいます
今回の用途では
ブラウザは関係ないので
nodejsを使います
prismaはnodejsで使えます
prismaでテーブルの定義を記述します
そしてnodejsで
jsonを読み込み
videoテーブルに保存するコードを書きます
これを実行すると
2500ほどの動画データを
データベースに保存できます
コメントのJSONも
同様にしてデータベースに保存します
これでデータベースが準備できました
最後にヒカキンのチャンネルIDを調べておき
SQLを書きます
ヒカキンのコメントを取得する
SQLはこのようになります
これをローカルで起動した
MySQLサーバに対して
実行します
そうするとヒカキンのコメントを
取得できました
900万コメントから
ヒカキンのコメントは7つでした
これを手作業で見つけるのは
難しいでしょう
今回の動画が勉強になった
おもしろいと思った方は
チャンネル登録・高評価を
お願いします
ヒカキンがしたコメントをどうやって調べたか
実はプログラミングをクソ使っています
今からお前らでもわかるように
プロのエンジニアである私が
クソわかりやすい言葉で説明します
動画では東海オンエアのサムネイルを
ランダムのスライドショーで表示しておくので
プログラミングわかんねと思ったら
とりあえずサムネイルをぼけっと見ておいてください
今回東海オンエアのメインチャンネルにある
すべての通常動画についているコメントを収集しました
ライブとショート動画は除いていますが
コメント総数は900万件以上あります
クソ多いです
東海オンエアの視聴者は本当によくコメントします
クソ多いので
手作業でこの中からヒカキンのコメントを
探すのは不可能です
そこでプログラミングの出番です
プログラミングは
プログラムを書くことを指します
コンピュータをこき使うために
人間はプログラムを書いて
コンピュータに命令するんです
コンピュータは単純作業がクソ得意です
というか単純作業しかできません
0と1しかわからないので
だから今回の企画に向いています
コメントがヒカキンのコメントかどうかを
判断するだけなので
クソ単純作業なんです
ただ量がとんでもなく多いので人間には難しい
一方コンピュータは
疲れてやめることはありません
では具体的な作業手順を説明します
手順１。東海オンエアの全ての動画IDを収集
手順２。各動画のコメントを収集
手順３。収集した動画とコメントをデータベースに保存
最後にSQLを書いてヒカキンのコメントを抽出します
データベースとはデータの保存や取得を
簡単にできるようにしたシステムのことです
SQLはデータベースを操作するために使います
プログラミング言語ではないですが
エンジニアの仕事でデータベースを扱うときは
よく使うものです
まず手順１です
youtubeではすべての動画はIDを持っています
IDは動画と動画を見分けるための名前みたいなものです
普通に考えると
動画のタイトルで良さそうですが
youtubeでは他の人が作った動画と
同じタイトルをつけることができます
これだと見分けがつかないのでIDに使えません
youtubeではIDにこのような文字列を使っています
この文字はクソ難しい数学を作って生成されています
今回は理解する必要はないので
わけのわからない文字だと思っていてください
そしてチャンネルにもチャンネルIDがあります
まず東海オンエアのメインチャンネルのIDを調べます
このサイトで調べました
このフォームに
チャンネルのURLを入力します
これでチャンネルIDがわかります
次にプログラムを書いて
東海オンエアメインチャンネルの動画をIDを収集します
プログラミング言語はpythonを使います
python以外の言語でも
可能ですが
pythonが今回使いやすかったので
pythonを使います
まずpythonを簡単に動かすための準備をします
Google Driveを開いて
Google Colabのファイルを作成
そして
!pip3 install scrapetube
を入力します
そうすると
scrapetubeというライブラリがインストールできます
ライブラリとは便利プログラムをまとめたもの
インストールはGoogle Colabの環境に
プログラムをダウンロードして使える状態に
することを言います
インストールはちょうど
冷凍食品をレンジでチンして
食べられる状態にすることに
似ています
そしてpythonのプログラムを書いて
動画をIDをテキストファイルに保存します
わけわからないと思いますが
概要欄にgoogle colabの
URLを置いておくので
それを使ってください
このプログラムは何をしているかというと
パソコンで東海オンエアの
動画一覧を見るときに
スクロールすると
古い動画が表示されます
またさらにスクロールすると
古い動画が表示されます
このスクロール操作は
普通は人間がやらないといけないですが
実はコンピュータに命令すれば
コンピュータが自動でやってくれます
その命令をpythonで書いています
自分で書くのはクソ大変なので
ライブラリを使っています
ライブラリは海外の開発者が
作っています
動画IDは動画のURLに含まれています
URLは動画が置いてある場所を示す物です
Chromeでスクロールするたびに
動画が表示されますが
ここのリンクがURLになっています
このURLを読む行為も
コンピュータに命令することができます
なのでスクロールするたびに
動画IDをURLから調べて
それをテキストファイルに保存しています
これで東海オンエアの通常動画の
動画IDを収集できました
2561本の動画がありました
手順２では各動画のコメントを収集します
ここでは別のライブラリを使います
youtube-comment-downloaderです
パソコンでyoutubeの動画を開くと
コメントが表示されます
これもスクロールすると
コメントがさらに表示される仕組みです
動画IDの収集と同様に
コメントにおいても
スクロールを自動化して
取集します
つまりpythonでプログラムを書き
プログラムよって
Chromeのようなブラウザを開き
動画のURLにアクセスし
コメントを表示して
それを保存。保存できたら
されにスクロールそして新しいコメントが
表示されるのでまた保存
一番古いコメントが
表示されるまでこれを繰り返します
python経由で
ブラウザを使うときは
ヘッドレスブラウザを使います
これは見た目がないブラウザです
人間が使うときはブラウザは見た目がないと
使えませんがコンピュータが操作するときは
プログラムによる命令だけで
操作できるので見た目が不要です
なのでヘッドレスブラウザを使います
ですのでchromeなどの
ブラウザが起動するわけではありません
プログラムはこのような感じです
収集したプログラムは
JSONで保存されます
JSONはデータの種類とその値を
まとめて書く形式のことを言います
よく使います
東海オンエアの動画は数千のコメントが付きます
1つの動画を収集するのに
数分かかることもあるので
2500もの動画のコメントを
すべて収集するのは結構大変です
処理を高速化するために
並列処理のプログラムを
書いたりしました
このあたりは
自分で書くのが大変なので
Chat GPT4の力を借りてます
手順３。収集した動画とコメントをデータベースに保存
ダウンロードしたJSONを使って
それをMySQLというデータベースに保存します
まずテーブルを作ります
テーブルはデータのまとまりです
Video,Channel,Commentを作りました
まず全ての動画をvideoテーブルに
保存します
事前に保存しておいた
動画IDのテキストファイルを使います
そしてまた新しいライブラリ
pytubeを使います
これを使えば動画IDから
動画の情報を取得してJSONで保存できます
例えば動画の閲覧数、公開日時などがわかります
次に動画のJSONをデータベースに保存します
直接SQLを書いても良いのですが
大変なので
prismaというライブラリを使います
prismaはjavascriptで動きます
ブラウザなどのクライアントサイドで
動くjavascriptに対して
サーバーサイドで動くjavascriptを
nodejsといいます
今回の用途では
ブラウザは関係ないので
nodejsを使います
prismaはnodejsで使えます
prismaでテーブルの定義を記述します
そしてnodejsで
jsonを読み込み
videoテーブルに保存する
コードを書きます
これを実行すると
2500ほどの動画データを
データベースに保存できます
コメントのJSONも
同様にしてデータベース保存します
これでデータベースが準備できました
最後にヒカキンのチャンネルIDを調べておき
SQLを書きます
ヒカキンのコメントを取得する
SQLはこのようになります
これをローカルで起動した
MySQLサーバに対して
実行します
そうするとヒカキンのコメントを
取得できました
900万コメントから
ヒカキンのコメントは7つでした
これを手作業で見つけるのは
難しいでしょう
今回の動画が勉強になった
おもしろいと思った方は
チャンネル登録・高評価を
お願いします
1
00:04:09,01 --> 00:04:13,48
ヒカキンがしたコメントをどうやって調べたか

2
00:04:13,48 --> 00:04:17,32
実はプログラミングをクソ使っています

3
00:04:17,32 --> 00:04:20,30
今からお前らでもわかるように

4
00:04:20,30 --> 00:04:23,07
プロのエンジニアである私が

5
00:04:23,07 --> 00:04:26,48
クソわかりやすい言葉で説明します

6
00:04:26,48 --> 00:04:30,11
動画では東海オンエアのサムネイルを

7
00:04:30,11 --> 00:04:34,58
ランダムのスライドショーで表示しておくので

8
00:04:34,58 --> 00:04:37,99
プログラミングわかんねと思ったら

9
00:04:37,99 --> 00:04:43,11
とりあえずサムネイルをぼけっと見ておいてください

10
00:04:43,11 --> 00:04:47,37
今回東海オンエアのメインチャンネルにある

11
00:04:47,37 --> 00:04:52,70
すべての通常動画についているコメントを収集しました

12
00:04:52,70 --> 00:04:56,54
ライブとショート動画は除いていますが

13
00:04:56,54 --> 00:05:00,38
コメント総数は900万件以上あります

14
00:05:00,38 --> 00:05:01,65
クソ多いです

15
00:05:01,65 --> 00:05:06,56
東海オンエアの視聴者は本当によくコメントします

16
00:05:06,56 --> 00:05:07,84
クソ多いので

17
00:05:07,84 --> 00:05:11,89
手作業でこの中からヒカキンのコメントを

18
00:05:11,89 --> 00:05:13,80
探すのは不可能です

19
00:05:13,80 --> 00:05:17,00
そこでプログラミングの出番です

20
00:05:17,00 --> 00:05:21,90
プログラミングはプログラムを書くことを指します

21
00:05:21,90 --> 00:05:24,89
コンピュータをこき使うために

22
00:05:24,89 --> 00:05:30,43
人間はプログラムを書いてコンピュータに命令するんです

23
00:05:30,43 --> 00:05:34,27
コンピュータは単純作業がクソ得意です

24
00:05:34,27 --> 00:05:40,02
というか0と1しかわからないので単純作業しかできません

25
00:05:40,02 --> 00:05:43,22
だから今回の企画に向いています

26
00:05:43,22 --> 00:05:49,19
コメントがヒカキンのコメントかどうかを判断するだけなので

27
00:05:49,19 --> 00:05:51,32
クソ単純作業なんです

28
00:05:51,32 --> 00:05:55,80
ただ量がとんでもなく多いので人間には難しい

29
00:05:55,80 --> 00:06:00,70
一方コンピュータは疲れてやめることはありません

30
00:06:00,70 --> 00:06:04,11
では具体的な作業手順を説明します

31
00:06:04,11 --> 00:06:08,37
手順１。東海オンエアの全ての動画IDを収集

32
00:06:08,37 --> 00:06:11,57
手順２。各動画のコメントを収集

33
00:06:11,57 --> 00:06:16,90
手順３。収集した動画とコメントをデータベースに保存

34
00:06:16,90 --> 00:06:21,91
最後にSQLを書いてヒカキンのコメントを抽出します

35
00:06:21,91 --> 00:06:25,75
データベースとはデータの保存や取得を

36
00:06:25,75 --> 00:06:30,01
簡単にできるようにしたシステムのことです

37
00:06:30,01 --> 00:06:34,38
SQLはデータベースを操作するために使います

38
00:06:34,38 --> 00:06:37,79
プログラミング言語ではないですが

39
00:06:37,79 --> 00:06:43,97
エンジニアの仕事でデータベースを扱うときはよく使うものです

40
00:06:43,97 --> 00:06:45,46
まず手順１です

41
00:06:45,46 --> 00:06:49,83
youtubeではすべての動画はIDを持っています

42
00:06:49,83 --> 00:06:55,16
IDは動画と動画を見分けるための名前みたいなものです

43
00:06:55,16 --> 00:06:59,85
普通に考えると動画のタイトルで良さそうですが

44
00:06:59,85 --> 00:07:03,15
youtubeでは他の人が作った動画と

45
00:07:03,15 --> 00:07:06,78
同じタイトルをつけることができます

46
00:07:06,78 --> 00:07:11,25
これだと見分けがつかないのでIDに使えません

47
00:07:11,25 --> 00:07:16,05
youtubeではIDにこのような文字列を使っています

48
00:07:16,05 --> 00:07:21,17
この文字はクソ難しい数学を使って生成されています

49
00:07:21,17 --> 00:07:24,15
今回は理解する必要はないので

50
00:07:24,15 --> 00:07:28,63
わけのわからない文字だと思っていてください

51
00:07:28,63 --> 00:07:33,10
そしてチャンネルにもチャンネルIDがあります

52
00:07:33,10 --> 00:07:38,22
まず東海オンエアのメインチャンネルのIDを調べます

53
00:07:38,22 --> 00:07:40,56
このサイトで調べました

54
00:07:40,56 --> 00:07:44,93
このフォームにチャンネルのURLを入力します

55
00:07:44,93 --> 00:07:48,13
これでチャンネルIDがわかります

56
00:07:48,13 --> 00:07:50,48
次にプログラムを書いて

57
00:07:50,48 --> 00:07:55,59
東海オンエアメインチャンネルの動画IDを収集します

58
00:07:55,59 --> 00:07:59,43
プログラミング言語はpythonを使います

59
00:07:59,43 --> 00:08:02,63
python以外の言語でも可能ですが

60
00:08:02,63 --> 00:08:05,82
pythonが今回使いやすかったので

61
00:08:05,82 --> 00:08:07,53
pythonを使います

62
00:08:07,53 --> 00:08:12,00
まずpythonを簡単に動かすための準備をします

63
00:08:12,00 --> 00:08:14,24
Google Driveを開いて

64
00:08:14,24 --> 00:08:17,33
Google Colabのファイルを作成

65
00:08:17,33 --> 00:08:22,24
そして!pip3 install scrapetubeを入力します

66
00:08:22,24 --> 00:08:28,42
そうするとscrapetubeというライブラリがインストールできます

67
00:08:28,42 --> 00:08:32,89
ライブラリとは便利プログラムをまとめたもの

68
00:08:32,89 --> 00:08:36,62
インストールはGoogle Colabの環境に

69
00:08:36,62 --> 00:08:42,81
プログラムをダウンロードして使える状態にすることを言います

70
00:08:42,81 --> 00:08:45,15
インストールはちょうど

71
00:08:45,15 --> 00:08:47,92
冷凍食品をレンジでチンして

72
00:08:47,92 --> 00:08:51,76
食べられる状態にすることに似ています

73
00:08:51,76 --> 00:08:55,17
そしてpythonのプログラムを書いて

74
00:08:55,17 --> 00:08:59,22
動画をIDをテキストファイルに保存します

75
00:08:59,22 --> 00:09:01,99
わけわからないと思いますが

76
00:09:01,99 --> 00:09:04,44
概要欄にgoogle colabの

77
00:09:04,44 --> 00:09:08,60
URLを置いておくのでそれを使ってください

78
00:09:08,60 --> 00:09:12,65
このプログラムは何をしているかというと

79
00:09:12,65 --> 00:09:15,21
パソコンで東海オンエアの

80
00:09:15,21 --> 00:09:19,04
動画一覧を見るときにスクロールすると

81
00:09:19,04 --> 00:09:21,39
古い動画が表示されます

82
00:09:21,39 --> 00:09:24,16
またさらにスクロールすると

83
00:09:24,16 --> 00:09:26,50
古い動画が表示されます

84
00:09:26,50 --> 00:09:28,64
このスクロール操作は

85
00:09:28,64 --> 00:09:32,47
普通は人間がやらないといけないですが

86
00:09:32,47 --> 00:09:35,46
実はコンピュータに命令すれば

87
00:09:35,46 --> 00:09:39,08
コンピュータが自動でやってくれます

88
00:09:39,08 --> 00:09:42,28
その命令をpythonで書いています

89
00:09:42,28 --> 00:09:45,26
自分で書くのはクソ大変なので

90
00:09:45,26 --> 00:09:47,82
ライブラリを使っています

91
00:09:47,82 --> 00:09:51,87
ライブラリは海外の開発者が作っています

92
00:09:51,87 --> 00:09:55,39
動画IDは動画のURLに含まれています

93
00:09:55,39 --> 00:09:59,33
URLは動画が置いてある場所を示す物です

94
00:09:59,33 --> 00:10:02,31
Chromeでスクロールするたびに

95
00:10:02,31 --> 00:10:04,45
動画が表示されますが

96
00:10:04,45 --> 00:10:07,75
ここのリンクがURLになっています

97
00:10:07,75 --> 00:10:13,61
このURLを読む行為もコンピュータに命令することができます

98
00:10:13,61 --> 00:10:16,38
なのでスクロールするたびに

99
00:10:16,38 --> 00:10:22,67
動画IDをURLから調べてそれをテキストファイルに保存しています

100
00:10:22,67 --> 00:10:25,87
これで東海オンエアの通常動画の

101
00:10:25,87 --> 00:10:28,21
動画IDを収集できました

102
00:10:28,21 --> 00:10:31,20
2561本の動画がありました

103
00:10:31,20 --> 00:10:35,25
手順２では各動画のコメントを収集します

104
00:10:35,25 --> 00:10:38,66
ここでは別のライブラリを使います

105
00:10:38,66 --> 00:10:42,07
youtube-comment-downloaderです

106
00:10:42,07 --> 00:10:45,37
パソコンでyoutubeの動画を開くと

107
00:10:45,37 --> 00:10:47,72
コメントが表示されます

108
00:10:47,72 --> 00:10:50,06
これもスクロールすると

109
00:10:50,06 --> 00:10:53,90
コメントがさらに表示される仕組みです

110
00:10:53,90 --> 00:10:57,95
動画IDの収集と同様にコメントにおいても

111
00:10:57,95 --> 00:11:01,36
スクロールを自動化して収集します

112
00:11:01,36 --> 00:11:04,56
つまりpythonでプログラムを書き

113
00:11:04,56 --> 00:11:09,46
プログラムによってChromeのようなブラウザを開き

114
00:11:09,46 --> 00:11:13,62
動画のURLにアクセスしコメントを表示して

115
00:11:13,62 --> 00:11:16,17
それを保存。保存できたら

116
00:11:16,17 --> 00:11:20,22
されにスクロールそして新しいコメントが

117
00:11:20,22 --> 00:11:22,57
表示されるのでまた保存

118
00:11:22,57 --> 00:11:24,49
一番古いコメントが

119
00:11:24,49 --> 00:11:27,90
表示されるまでこれを繰り返します

120
00:11:27,90 --> 00:11:31,09
プログラムはこのような感じです

121
00:11:31,09 --> 00:11:33,23
収集したプログラムは

122
00:11:33,23 --> 00:11:35,14
JSONで保存されます

123
00:11:35,14 --> 00:11:38,13
JSONはデータの種類とその値を

124
00:11:38,13 --> 00:11:41,54
まとめて書く形式のことを言います

125
00:11:41,54 --> 00:11:42,82
クソ使います

126
00:11:42,82 --> 00:11:47,51
東海オンエアの動画は数千のコメントが付きます

127
00:11:47,51 --> 00:11:50,07
1つの動画を収集するのに

128
00:11:50,07 --> 00:11:52,62
数分かかることもあるので

129
00:11:52,62 --> 00:11:55,61
2500もの動画のコメントを

130
00:11:55,61 --> 00:11:58,80
すべて収集するのはクソ大変です

131
00:11:58,80 --> 00:12:01,15
処理を高速化するために

132
00:12:01,15 --> 00:12:03,49
並列処理のプログラムを

133
00:12:03,49 --> 00:12:05,20
書いたりしました

134
00:12:05,20 --> 00:12:09,04
このあたりは自分で書くのが大変なので

135
00:12:09,04 --> 00:12:11,91
Chat GPT4の力を借りてます

136
00:12:11,91 --> 00:12:17,24
手順３。収集した動画とコメントをデータベースに保存

137
00:12:17,24 --> 00:12:20,23
ダウンロードしたJSONを使って

138
00:12:20,23 --> 00:12:24,60
それをMySQLというデータベースに保存します

139
00:12:24,60 --> 00:12:26,94
まずテーブルを作ります

140
00:12:26,94 --> 00:12:30,14
テーブルはデータのまとまりです

141
00:12:30,14 --> 00:12:33,87
Video,Channel,Commentを作りました

142
00:12:33,87 --> 00:12:37,17
まず全ての動画をvideoテーブルに

143
00:12:37,17 --> 00:12:38,24
保存します

144
00:12:38,24 --> 00:12:40,37
事前に保存しておいた

145
00:12:40,37 --> 00:12:43,99
動画IDのテキストファイルを使います

146
00:12:43,99 --> 00:12:46,77
そしてまた新しいライブラリ

147
00:12:46,77 --> 00:12:50,18
pytube（パイチューブ）を使います

148
00:12:50,18 --> 00:12:52,52
これを使えば動画IDから

149
00:12:52,52 --> 00:12:56,57
動画の情報を取得してJSONで保存できます

150
00:12:56,57 --> 00:13:01,26
例えば動画の閲覧数、公開日時などがわかります

151
00:13:01,26 --> 00:13:05,52
次に動画のJSONをデータベースに保存します

152
00:13:05,52 --> 00:13:08,61
直接SQLを書いても良いのですが

153
00:13:08,61 --> 00:13:09,68
大変なので

154
00:13:09,68 --> 00:13:13,09
prismaというライブラリを使います

155
00:13:13,09 --> 00:13:16,07
prismaはjavascriptで動きます

156
00:13:16,07 --> 00:13:19,70
ブラウザなどのクライアントサイドで

157
00:13:19,70 --> 00:13:22,04
動くjavascriptに対して

158
00:13:22,04 --> 00:13:25,45
サーバーサイドで動くjavascriptを

159
00:13:25,45 --> 00:13:29,29
nodejs（ノードジェイエス）といいます

160
00:13:29,29 --> 00:13:30,78
今回の用途では

161
00:13:30,78 --> 00:13:33,13
ブラウザは関係ないので

162
00:13:33,13 --> 00:13:34,83
nodejsを使います

163
00:13:34,83 --> 00:13:37,39
prismaはnodejsで使えます

164
00:13:37,39 --> 00:13:41,01
prismaでテーブルの定義を記述します

165
00:13:41,01 --> 00:13:42,51
そしてnodejsで

166
00:13:42,51 --> 00:13:44,00
jsonを読み込み

167
00:13:44,00 --> 00:13:48,15
videoテーブルに保存するコードを書きます

168
00:13:48,15 --> 00:13:49,86
これを実行すると

169
00:13:49,86 --> 00:13:52,63
2500ほどの動画データを

170
00:13:52,63 --> 00:13:55,40
データベースに保存できます

171
00:13:55,40 --> 00:13:57,11
コメントのJSONも

172
00:13:57,11 --> 00:14:00,73
同様にしてデータベースに保存します

173
00:14:00,73 --> 00:14:04,35
これでデータベースが準備できました

174
00:14:04,35 --> 00:14:08,62
最後にヒカキンのチャンネルIDを調べておき

175
00:14:08,62 --> 00:14:10,00
SQLを書きます

176
00:14:10,00 --> 00:14:12,99
ヒカキンのコメントを取得する

177
00:14:12,99 --> 00:14:15,44
SQLはこのようになります

178
00:14:15,44 --> 00:14:18,00
これをローカルで起動した

179
00:14:18,00 --> 00:14:20,02
MySQLサーバに対して

180
00:14:20,02 --> 00:14:21,09
実行します

181
00:14:21,09 --> 00:14:24,29
そうするとヒカキンのコメントを

182
00:14:24,29 --> 00:14:25,78
取得できました

183
00:14:25,78 --> 00:14:27,91
900万コメントから

184
00:14:27,91 --> 00:14:31,11
ヒカキンのコメントは7つでした

185
00:14:31,11 --> 00:14:33,88
これを手作業で見つけるのは

186
00:14:33,88 --> 00:14:35,37
難しいでしょう

187
00:14:35,37 --> 00:14:37,93
今回の動画が勉強になった

188
00:14:37,93 --> 00:14:40,27
おもしろいと思った方は

189
00:14:40,27 --> 00:14:42,83
チャンネル登録・高評価を

190
00:14:42,83 --> 00:14:44,11
お願いします

